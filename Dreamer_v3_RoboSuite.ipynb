{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarStryke21/NaturalDreamer/blob/main/Dreamer_v3_RoboSuite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up Colab Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "d7pGBxXoixhv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'NaturalDreamer' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: '/content/NaturalDreamer/'\n",
            "/home/achulawa/Projects/NaturalDreamer\n"
          ]
        }
      ],
      "source": [
        "# Clone the Natural Dreamer repository\n",
        "\n",
        "!git clone https://github.com/FarStryke21/NaturalDreamer.git\n",
        "\n",
        "%cd /content/NaturalDreamer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "eLYRcvCPkzDP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: robosuite in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (1.5.1)\n",
            "Requirement already satisfied: attridict in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (0.0.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (2.2.5)\n",
            "Requirement already satisfied: numba>=0.49.1 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (0.61.2)\n",
            "Requirement already satisfied: scipy>=1.2.3 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (1.15.3)\n",
            "Requirement already satisfied: mujoco>=3.2.3 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (3.3.2)\n",
            "Requirement already satisfied: mink>=0.0.5 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (0.0.10)\n",
            "Requirement already satisfied: Pillow in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (10.4.0)\n",
            "Requirement already satisfied: opencv-python in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (4.11.0.86)\n",
            "Requirement already satisfied: pynput in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (1.8.1)\n",
            "Requirement already satisfied: termcolor in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (3.1.0)\n",
            "Requirement already satisfied: pytest in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (8.3.5)\n",
            "Requirement already satisfied: tqdm in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from robosuite) (4.67.1)\n",
            "Requirement already satisfied: PyYAML==6.0.1 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from attridict) (6.0.1)\n",
            "Requirement already satisfied: qpsolvers>=4.3.1 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from qpsolvers[daqp]>=4.3.1->mink>=0.0.5->robosuite) (4.7.0)\n",
            "Requirement already satisfied: typing_extensions in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from mink>=0.0.5->robosuite) (4.13.2)\n",
            "Requirement already satisfied: absl-py in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from mujoco>=3.2.3->robosuite) (2.2.2)\n",
            "Requirement already satisfied: etils[epath] in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from mujoco>=3.2.3->robosuite) (1.12.2)\n",
            "Requirement already satisfied: glfw in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from mujoco>=3.2.3->robosuite) (2.9.0)\n",
            "Requirement already satisfied: pyopengl in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from mujoco>=3.2.3->robosuite) (3.1.9)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from numba>=0.49.1->robosuite) (0.44.0)\n",
            "Requirement already satisfied: daqp>=0.5.1 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from qpsolvers[daqp]>=4.3.1->mink>=0.0.5->robosuite) (0.7.1)\n",
            "Requirement already satisfied: fsspec in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from etils[epath]->mujoco>=3.2.3->robosuite) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from etils[epath]->mujoco>=3.2.3->robosuite) (6.5.2)\n",
            "Requirement already satisfied: zipp in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from etils[epath]->mujoco>=3.2.3->robosuite) (3.21.0)\n",
            "Requirement already satisfied: six in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from pynput->robosuite) (1.17.0)\n",
            "Requirement already satisfied: evdev>=1.3 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from pynput->robosuite) (1.9.2)\n",
            "Requirement already satisfied: python-xlib>=0.17 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from pynput->robosuite) (0.33)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from pytest->robosuite) (1.3.0)\n",
            "Requirement already satisfied: iniconfig in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from pytest->robosuite) (2.1.0)\n",
            "Requirement already satisfied: packaging in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from pytest->robosuite) (25.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from pytest->robosuite) (1.6.0)\n",
            "Requirement already satisfied: tomli>=1 in /home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages (from pytest->robosuite) (2.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install robosuite attridict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Robosuite Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "WCbX6P2XklGx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set logging level: Console=ERROR | File=None\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym # For wrappers\n",
        "import torch\n",
        "import argparse\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Robosuite imports\n",
        "import robosuite as suite\n",
        "from robosuite.wrappers import GymWrapper\n",
        "\n",
        "# Project-specific imports\n",
        "from dreamer import Dreamer\n",
        "from utils import loadConfig, seedEverything, plotMetrics, saveLossesToCSV, ensureParentFolders\n",
        "from envs import getEnvProperties, GymPixelsProcessingWrapper, CleanGymWrapper, ImageExtractWrapper # Using getEnvProperties from envs.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UCqdB28Blmzm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "koH01dgMl7ur"
      },
      "outputs": [],
      "source": [
        "# Load experiment config\n",
        "configFile = \"robosuite-lift-panda.yml\"\n",
        "config = loadConfig(configFile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sWnvbQ0YmiHI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded config from file: robosuite-lift-panda.yml\n",
            "Using seed: 1234\n"
          ]
        }
      ],
      "source": [
        "# Set seed through the environment\n",
        "seedEverything(config.seed)\n",
        "print(f\"Loaded config from file: {configFile}\")\n",
        "print(f\"Using seed: {config.seed}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hs8T4Z7emwJn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run name: Lift_Panda_lift_panda_test\n",
            "Metrics will be saved to: metrics/Lift_Panda_lift_panda_test.csv\n",
            "Plots will be saved to: plots/Lift_Panda_lift_panda_test.html\n",
            "Checkpoints will be saved to: checkpoints/Lift_Panda_lift_panda_test\n",
            "Videos will be saved to: videos\n"
          ]
        }
      ],
      "source": [
        "# Setup files and folder logging\n",
        "runName = f\"{config.environmentName}_{config.robotName}_{config.runName}\"\n",
        "\n",
        "# Define paths for checkpoints, metrics, plots, and videos\n",
        "checkpointFolder = os.path.join(config.folderNames.checkpointsFolder, runName)\n",
        "metricsFilename = os.path.join(config.folderNames.metricsFolder, f\"{runName}.csv\")\n",
        "plotFilename = os.path.join(config.folderNames.plotsFolder, f\"{runName}.html\")\n",
        "checkpointFilenameBase = os.path.join(checkpointFolder, runName) # Checkpoints will be saved in a subfolder per run\n",
        "videoFilenameBase = os.path.join(config.folderNames.videosFolder, runName)\n",
        "\n",
        "# Ensure parent directories for all output files exist\n",
        "ensureParentFolders(metricsFilename, plotFilename, checkpointFilenameBase, videoFilenameBase)\n",
        "print(f\"Run name: {runName}\")\n",
        "print(f\"Metrics will be saved to: {metricsFilename}\")\n",
        "print(f\"Plots will be saved to: {plotFilename}\")\n",
        "print(f\"Checkpoints will be saved to: {checkpointFolder}\")\n",
        "print(f\"Videos will be saved to: {config.folderNames.videosFolder}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "thJZlGPHnE4W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Robosuite training environment...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n",
            "/home/achulawa/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        }
      ],
      "source": [
        "print(\"Initializing Robosuite training environment...\")\n",
        "robosuite_env_train = suite.make(\n",
        "    env_name=config.environmentName,\n",
        "    robots=config.robotName,\n",
        "    controller_configs=suite.load_composite_controller_config(controller=config.controllerName),\n",
        "    has_renderer=False,  # No on-screen rendering for training\n",
        "    has_offscreen_renderer=config.useCameraObs, # True if using camera observations for the encoder\n",
        "    use_camera_obs=config.useCameraObs,\n",
        "    camera_names=config.cameraName,\n",
        "    camera_heights=config.cameraHeight, # Robosuite will render at this resolution\n",
        "    camera_widths=config.cameraWidth,\n",
        "    reward_shaping=config.rewardShaping,\n",
        "    control_freq=config.controlFreq,\n",
        "    horizon=config.horizon,\n",
        ")\n",
        "\n",
        "train_env_keys = [f\"{config.cameraName}_image\"]\n",
        "env = GymWrapper(robosuite_env_train, keys=train_env_keys, flatten_obs=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6NsXsmz_oMt3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Observation Space: Dict('agentview_image': Box(0, 255, (64, 64, 3), uint8))\n",
            "New Observation SpaceBox(0.0, 1.0, (3, 64, 64), float32)\n",
            "Robosuite training environment initialized.\n"
          ]
        }
      ],
      "source": [
        "# Apply observation wrappers\n",
        "print(f\"Original Observation Space: {env.observation_space}\")\n",
        "env = ImageExtractWrapper(env, image_key=train_env_keys[0]) # Convert Dictionary Observation to Image Observation -> Box(0, 255, (64, 64, 3), uint8)\n",
        "env = gym.wrappers.ResizeObservation(env, (config.cameraHeight, config.cameraWidth)) # Resize image observation size -> Box(0, 255, (64, 64, 3), uint8)\n",
        "env = GymPixelsProcessingWrapper(env) # Rearrange Observation space -> Box(0.0, 1.0, (3, 64, 64), float32\n",
        "env = CleanGymWrapper(env) # Clean Gym Wrapper -> Box(0.0, 1.0, (3, 64, 64), float32)\n",
        "print(f\"New Observation Space{env.observation_space}\")\n",
        "print(\"Robosuite training environment initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uCkjN6Tjxm93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Robosuite evaluation environment...\n"
          ]
        }
      ],
      "source": [
        "print(\"Initializing Robosuite evaluation environment...\")\n",
        "robosuite_env_eval = suite.make(\n",
        "    env_name=config.environmentName,\n",
        "    robots=config.robotName,\n",
        "    controller_configs=suite.load_composite_controller_config(controller=config.controllerName),\n",
        "    has_renderer=config.evaluationRender,  # Enable for video saving if needed\n",
        "    has_offscreen_renderer=config.useCameraObs or config.evaluationRender, # Offscreen needed for rgb_array for video\n",
        "    use_camera_obs=config.useCameraObs,\n",
        "    camera_names=config.cameraName,\n",
        "    camera_heights=config.cameraHeight,\n",
        "    camera_widths=config.cameraWidth,\n",
        "    reward_shaping=config.rewardShaping, # Usually good to keep consistent with training\n",
        "    control_freq=config.controlFreq,\n",
        "    horizon=config.horizon,\n",
        "    # render_camera=config.cameraName # Or a different camera like \"frontview\" for videos\n",
        ")\n",
        "eval_env_keys = [f\"{config.cameraName}_image\"]\n",
        "envEvaluation = GymWrapper(robosuite_env_eval, keys=eval_env_keys, flatten_obs=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GQThmG-xx9Sy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Observation Space: Dict('agentview_image': Box(0, 255, (64, 64, 3), uint8))\n",
            "New Observation SpaceBox(0.0, 1.0, (3, 64, 64), float32)\n",
            "Robosuite training environment initialized.\n"
          ]
        }
      ],
      "source": [
        "# Apply observation wrappers\n",
        "print(f\"Original Observation Space: {envEvaluation.observation_space}\")\n",
        "envEvaluation = ImageExtractWrapper(envEvaluation, image_key=train_env_keys[0]) # Convert Dictionary Observation to Image Observation -> Box(0, 255, (64, 64, 3), uint8)\n",
        "envEvaluation = gym.wrappers.ResizeObservation(envEvaluation, (config.cameraHeight, config.cameraWidth)) # Resize image observation size -> Box(0, 255, (64, 64, 3), uint8)\n",
        "envEvaluation = GymPixelsProcessingWrapper(envEvaluation) # Rearrange Observation space -> Box(0.0, 1.0, (3, 64, 64), float32\n",
        "envEvaluation = CleanGymWrapper(envEvaluation) # Clean Gym Wrapper -> Box(0.0, 1.0, (3, 64, 64), float32)\n",
        "print(f\"New Observation Space{envEvaluation.observation_space}\")\n",
        "print(\"Robosuite training environment initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PLB9IZb7yOY0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment Properties: Observation Shape (3, 64, 64), Action Size 7, Action Low [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], Action High [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "# This function should work with the wrapped environment\n",
        "observationShape, actionSize, actionLow, actionHigh = getEnvProperties(env)\n",
        "print(f\"Environment Properties: Observation Shape {observationShape}, Action Size {actionSize}, Action Low {actionLow}, Action High {actionHigh}\")\n",
        "if not config.useCameraObs:\n",
        "    print(\"Warning: 'useCameraObs' is False. The current Dreamer implementation primarily expects image observations for its Encoder. Ensure your network setup is appropriate for state-based observations if this is intended.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4a8M7024yZas"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Dreamer agent...\n"
          ]
        }
      ],
      "source": [
        "print(\"Initializing Dreamer agent...\")\n",
        "dreamer = Dreamer(observationShape, actionSize, actionLow, actionHigh, device, config.dreamer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumed training from checkpoint: checkpoints/Lift_Panda_lift_panda_test/Lift_Panda_lift_panda_test_5k.pth\n"
          ]
        }
      ],
      "source": [
        "if config.resume:\n",
        "    checkpointToLoadPath = os.path.join(checkpointFolder, f\"{runName}_{config.checkpointToLoad}.pth\")\n",
        "    try:\n",
        "        dreamer.loadCheckpoint(checkpointToLoadPath)\n",
        "        print(f\"Resumed training from checkpoint: {checkpointToLoadPath}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: Checkpoint not found at {checkpointToLoadPath}. Starting from scratch.\")\n",
        "else:\n",
        "    print(\"Starting training from scratch.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "VZiVVQL3yide"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buffer size after initial collection: 10000\n"
          ]
        }
      ],
      "source": [
        "dreamer.environmentInteraction(env, config.episodesBeforeStart, seed=config.seed)\n",
        "print(f\"Buffer size after initial collection: {len(dreamer.buffer)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0Gr8XQGZy2r7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for 100000 gradient steps, with 10000 outer iterations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:   5%|▍         | 499/10000 [41:31<13:10:38,  4.99s/it]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# Perform evaluation\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         video_path_suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m         evaluationScore \u001b[38;5;241m=\u001b[39m \u001b[43mdreamer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironmentInteraction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43menvEvaluation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumEvaluationEpisodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdreamer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotalEpisodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use a different seed for eval if desired\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43msaveVideo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfolderNames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideosFolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_path_suffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pass full path\u001b[39;49;00m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miter_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miterationsNum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Grad Steps \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdreamer\u001b[38;5;241m.\u001b[39mtotalGradientSteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Saved Checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrentCheckpointPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Eval Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluationScore\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mevaluationScore\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# print(f\"Replay Iteration {iter_idx+1}/{iterationsNum} | Grad Steps {dreamer.totalGradientSteps} | World Model Loss: {worldModelMetrics['loss']:.4f} | Behavior Loss: {behaviorMetrics['loss']:.4f}\")\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Collect more environment interactions\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/dreamer-v3/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Projects/NaturalDreamer/dreamer.py:192\u001b[0m, in \u001b[0;36mDreamer.environmentInteraction\u001b[0;34m(self, env, numEpisodes, seed, evaluation, saveVideo, filename, fps, macroBlockSize)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m saveVideo \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    191\u001b[0m     frame \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m--> 192\u001b[0m     targetHeight \u001b[38;5;241m=\u001b[39m (\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m macroBlockSize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mmacroBlockSize\u001b[38;5;241m*\u001b[39mmacroBlockSize \u001b[38;5;66;03m# getting rid of imagio warning\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     targetWidth \u001b[38;5;241m=\u001b[39m (frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m macroBlockSize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mmacroBlockSize\u001b[38;5;241m*\u001b[39mmacroBlockSize\n\u001b[1;32m    194\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mpad(frame, ((\u001b[38;5;241m0\u001b[39m, targetHeight \u001b[38;5;241m-\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), (\u001b[38;5;241m0\u001b[39m, targetWidth \u001b[38;5;241m-\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "iterationsNum = config.gradientSteps // config.replayRatio\n",
        "print(f\"Starting training for {config.gradientSteps} gradient steps, with {iterationsNum} outer iterations.\")\n",
        "\n",
        "for iter_idx in tqdm(range(iterationsNum), desc=\"Training Progress\"):\n",
        "    # Inner loop for gradient updates\n",
        "\n",
        "    for _ in range(config.replayRatio):\n",
        "\n",
        "        if len(dreamer.buffer) < dreamer.config.batchSize * dreamer.config.batchLength: # Ensure enough data for a full sequence batch\n",
        "            print(f\"Buffer has {len(dreamer.buffer)} samples, less than required {dreamer.config.batchSize * dreamer.config.batchLength}. Collecting more...\")\n",
        "            dreamer.environmentInteraction(env, 1, seed=(config.seed + dreamer.totalEpisodes if config.seed else None)) # Collect one more episode\n",
        "\n",
        "            if len(dreamer.buffer) < dreamer.config.batchSize * dreamer.config.batchLength:\n",
        "                continue # Skip training step if still not enough data\n",
        "\n",
        "        sampledData = dreamer.buffer.sample(dreamer.config.batchSize, dreamer.config.batchLength)\n",
        "        initialStates, worldModelMetrics = dreamer.worldModelTraining(sampledData)\n",
        "        behaviorMetrics = dreamer.behaviorTraining(initialStates)\n",
        "        dreamer.totalGradientSteps += 1\n",
        "\n",
        "        # Checkpoint saving and evaluation\n",
        "        if dreamer.totalGradientSteps % config.checkpointInterval == 0 and config.saveCheckpoints:\n",
        "            suffix = f\"{dreamer.totalGradientSteps // 1000:.0f}k\"\n",
        "            currentCheckpointPath = f\"{checkpointFilenameBase}_{suffix}.pth\"\n",
        "            dreamer.saveCheckpoint(currentCheckpointPath)\n",
        "\n",
        "            # Perform evaluation\n",
        "            video_path_suffix = f\"{runName}_{suffix}\"\n",
        "            evaluationScore = dreamer.environmentInteraction(\n",
        "                envEvaluation,\n",
        "                config.numEvaluationEpisodes,\n",
        "                seed=(config.seed + dreamer.totalEpisodes if config.seed else None), # Use a different seed for eval if desired\n",
        "                evaluation=True,\n",
        "                saveVideo=True,\n",
        "                filename=os.path.join(config.folderNames.videosFolder, video_path_suffix) # Pass full path\n",
        "            )\n",
        "            print(f\"Iter {iter_idx+1}/{iterationsNum} | Grad Steps {dreamer.totalGradientSteps} | Saved Checkpoint: {currentCheckpointPath} | Eval Score: {evaluationScore if evaluationScore is not None else 'N/A':>8.2f}\")\n",
        "        \n",
        "        # print(f\"Replay Iteration {iter_idx+1}/{iterationsNum} | Grad Steps {dreamer.totalGradientSteps} | World Model Loss: {worldModelMetrics['loss']:.4f} | Behavior Loss: {behaviorMetrics['loss']:.4f}\")\n",
        "\n",
        "    # Collect more environment interactions\n",
        "    mostRecentScore = dreamer.environmentInteraction(env, config.numInteractionEpisodes, seed=(config.seed + dreamer.totalEpisodes if config.seed else None))\n",
        "\n",
        "    # Save metrics\n",
        "    if config.saveMetrics:\n",
        "        metricsBase = {\n",
        "            \"envSteps\": dreamer.totalEnvSteps,\n",
        "            \"gradientSteps\": dreamer.totalGradientSteps,\n",
        "            \"totalReward\": mostRecentScore if mostRecentScore is not None else float('nan')\n",
        "        }\n",
        "        # Merge all metrics dictionaries\n",
        "        all_metrics = {**metricsBase, **worldModelMetrics, **behaviorMetrics}\n",
        "        saveLossesToCSV(metricsFilename, all_metrics)\n",
        "\n",
        "        # Plot metrics (can be slow, consider doing it less frequently if performance is an issue)\n",
        "        if dreamer.totalGradientSteps % (config.checkpointInterval * 5) == 0: # Plot less frequently\n",
        "              plotMetrics(f\"{metricsFilename}\", savePath=f\"{plotFilename}\", title=f\"{config.environmentName} {config.robotName} - {config.runName}\")\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# Final plot\n",
        "if config.saveMetrics:\n",
        "    plotMetrics(f\"{metricsFilename}\", savePath=f\"{plotFilename}\", title=f\"{config.environmentName} {config.robotName} - {config.runName} (Final)\")\n",
        "env.close()\n",
        "envEvaluation.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Git Management - Colab use only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf7VK6qq1CAY"
      },
      "outputs": [],
      "source": [
        "# Sync with colab\n",
        "!git config --global user.email \"aman.chulawala@gmail.com\"\n",
        "!git add .\n",
        "!git commit -m \"Colab Push -> Added Image Wrapper for robosuite\"\n",
        "!git push https://<PAT>@github.com/FarStryke21/NaturalDreamer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BRBTqoOQ4gsI"
      },
      "outputs": [],
      "source": [
        "# Video generation test\n",
        "envEvaluation.reset()\n",
        "frame = envEvaluation.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64, 3)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frame.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[247, 246, 241],\n",
              "        [247, 247, 242],\n",
              "        [247, 247, 242],\n",
              "        ...,\n",
              "        [252, 251, 247],\n",
              "        [252, 251, 247],\n",
              "        [252, 251, 247]],\n",
              "\n",
              "       [[247, 246, 241],\n",
              "        [247, 246, 242],\n",
              "        [247, 247, 242],\n",
              "        ...,\n",
              "        [252, 251, 247],\n",
              "        [252, 251, 247],\n",
              "        [252, 251, 247]],\n",
              "\n",
              "       [[247, 246, 241],\n",
              "        [247, 246, 242],\n",
              "        [247, 247, 242],\n",
              "        ...,\n",
              "        [252, 251, 247],\n",
              "        [252, 251, 247],\n",
              "        [252, 251, 247]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[115, 113, 110],\n",
              "        [116, 113, 110],\n",
              "        [116, 114, 110],\n",
              "        ...,\n",
              "        [115, 113, 110],\n",
              "        [116, 113, 110],\n",
              "        [116, 114, 110]],\n",
              "\n",
              "       [[116, 113, 110],\n",
              "        [116, 114, 110],\n",
              "        [116, 114, 111],\n",
              "        ...,\n",
              "        [116, 113, 110],\n",
              "        [116, 114, 110],\n",
              "        [116, 114, 110]],\n",
              "\n",
              "       [[116, 113, 110],\n",
              "        [116, 114, 111],\n",
              "        [116, 114, 111],\n",
              "        ...,\n",
              "        [116, 113, 110],\n",
              "        [115, 113, 110],\n",
              "        [116, 114, 111]]], shape=(64, 64, 3), dtype=uint8)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.6235392166750375)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dreamer.environmentInteraction(envEvaluation, \n",
        "                                1, \n",
        "                                seed=config.seed, \n",
        "                                evaluation=True,\n",
        "                                saveVideo=True,\n",
        "                                filename=os.path.join(config.folderNames.videosFolder, \"VIDEO_TEST\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMG+/7SQaweiTfHuvsCC0el",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dreamer-v3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
